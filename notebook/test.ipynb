{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3abc8466ffa112993b76a5ade2301bd1c4f0305fe3c4fc980a76b9731a196a27"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Watermark Distortions\n",
    "\n",
    "## List of Distortions\n",
    "- Identity\n",
    "- Dropout\n",
    "- Cropout\n",
    "- Crop\n",
    "- Resize\n",
    "- Gaussian Blur\n",
    "- JPEG Compression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import typing\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import distortions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(x: torch.FloatTensor):\n",
    "    x = x[0] if len(x.shape) == 4 else x\n",
    "    x = x.permute(1, 2, 0)\n",
    "    plt.imshow(x)\n",
    "\n",
    "\n",
    "def imsave(x: typing.List[torch.FloatTensor], path: str, nrow, pad: int):\n",
    "    torchvision.utils.save_image(x, path, nrow=nrow, padding=pad)\n",
    "\n",
    "\n",
    "def adjust_image_size(img :PIL.Image.Image) -> PIL.Image.Image:\n",
    "    w, h = img.size\n",
    "    nh, nw = h - h % 8, w - w % 8\n",
    "    return F.resize(img, (nh, nw))\n",
    "\n",
    "\n",
    "def get_image_tensor(path: str) -> torch.FloatTensor:\n",
    "    img = PIL.Image.open(path)\n",
    "    img = adjust_image_size(img)\n",
    "    return F.to_tensor(img)[None, ...]\n",
    "\n",
    "\n",
    "def padding_image(x: torch.FloatTensor, shape: tuple) -> torch.FloatTensor:\n",
    "    if x.shape == shape: return x\n",
    "    _, _, h, w = x.shape\n",
    "    out = torch.zeros(shape)\n",
    "    out[:, :, :h, :w] = x\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "identity\ndropout\ncropout\ncrop\nresize\ngaussian_blur\njpeg_mask\njpeg_drop\n"
     ]
    }
   ],
   "source": [
    "inp = get_image_tensor(\"../images/dog_03.jpg\")\n",
    "\n",
    "distortioners = {\n",
    "    \"identity\": distortions.Identity(),\n",
    "    \"dropout\": distortions.Dropout(0.3),\n",
    "    \"cropout\": distortions.Cropout(0.3),\n",
    "    \"crop\": distortions.Crop(0.3),\n",
    "    \"resize\": distortions.Resize(0.3),\n",
    "    \"gaussian_blur\": distortions.GaussianBlur(5, 2),\n",
    "    \"jpeg_mask\": distortions.JPEGMask(),\n",
    "    \"jpeg_drop\": distortions.JPEGDrop(),\n",
    "}\n",
    "\n",
    "outs = []\n",
    "for name, dis in distortioners.items():\n",
    "    print(name)\n",
    "    out = dis(inp, inp)\n",
    "    outs.append(padding_image(out, inp.shape))\n",
    "\n",
    "imsave(torch.cat(outs, dim=0), \"../images/distortions.jpg\", nrow=4, pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}